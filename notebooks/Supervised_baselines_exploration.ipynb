{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a000c3f9",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b1e8c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from scipy.stats.stats import pearsonr\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, f1_score, balanced_accuracy_score, mean_squared_error, r2_score\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74e0d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which datasets to read and write\n",
    "\n",
    "do_indian_pines = True \n",
    "do_salient_objects = True\n",
    "do_plastic_flakes = True\n",
    "do_soil_moisture = True\n",
    "do_foods = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9110b99a",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c8d6b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataset loading\n",
    "\n",
    "def load_datasets(Dataset):\n",
    "    \n",
    "    if Dataset == 'SM':\n",
    "        hyper_path = '../data/soil_moisture/hyperspectral_imagery/*npy'\n",
    "        hyper = np.load(glob.glob(hyper_path)[0])\n",
    "        gt_path = '../data/soil_moisture/gt_labels/*npy'\n",
    "        gt = np.load(glob.glob(gt_path)[0])\n",
    "        return hyper, gt\n",
    "    \n",
    "    if Dataset == 'IN':\n",
    "        hyper_path = '../data/indian_pines/hyperspectral_imagery/*npy'\n",
    "        hyper = np.load(glob.glob(hyper_path)[0])\n",
    "        gt_path = '../data/indian_pines/gt_labels/*npy'\n",
    "        gt = np.load(glob.glob(gt_path)[0])\n",
    "        return hyper, gt\n",
    "    \n",
    "    if Dataset == 'SO':\n",
    "        hyper_path = '../data/salient_objects/hyperspectral_imagery/*npy'\n",
    "        gt_path = '../data/salient_objects/gt_labels/*npy'\n",
    "        hypers=[]\n",
    "        gt_labels=[]\n",
    "        for i in range(len(glob.glob(hyper_path))):\n",
    "            hyper = np.load(glob.glob(hyper_path)[i])\n",
    "            hypers.append(hyper)\n",
    "            gt = np.load(glob.glob(gt_path)[i])\n",
    "            gt_labels.append(gt)\n",
    "        return hypers, gt_labels\n",
    "\n",
    "                          \n",
    "    if Dataset == 'PF':\n",
    "        hyper_path = '../data/plastic_flakes/hyperspectral_imagery/*npy'\n",
    "        gt_path = '../data/plastic_flakes/gt_labels/*npy'\n",
    "        hypers=[]\n",
    "        gt_labels=[]\n",
    "        for i in range(len(glob.glob(hyper_path))):\n",
    "            hyper = np.load(glob.glob(hyper_path)[i])\n",
    "            hypers.append(hyper)\n",
    "            gt = np.load(glob.glob(gt_path)[i])\n",
    "            gt_labels.append(gt)\n",
    "        return hypers, gt_labels\n",
    "    \n",
    "    if Dataset == 'Foods':\n",
    "        hyper_path = '../data/foods/hyperspectral_imagery/*npy'\n",
    "        gt_path = '../data/foods/gt_labels/*npy'\n",
    "        hypers=[]\n",
    "        gt_labels=[]\n",
    "        for i in range(len(glob.glob(hyper_path))):\n",
    "            hyper = np.load(glob.glob(hyper_path)[i])\n",
    "            hypers.append(hyper)\n",
    "            gt = np.load(glob.glob(gt_path)[i])\n",
    "            gt_labels.append(gt)\n",
    "        return hypers, gt_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88ebc51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, mean, std): \n",
    "    return (data - mean) / std\n",
    "\n",
    "\n",
    "def baseline_supervised_pass(data_fpath, labels_fpath, Dataset, random_subset=False, num_random_bands=15):\n",
    "    \n",
    "    # train val split\n",
    "    data = np.load(data_fpath)\n",
    "    if random_subset:\n",
    "        indices = np.random.randint(0, data.shape[1], num_random_bands)\n",
    "        data = data[:,indices]\n",
    "        \n",
    "    # print(data.shape)\n",
    "\n",
    "    labels = np.load(labels_fpath)\n",
    "    \n",
    "    if Dataset == 'SM':\n",
    "\n",
    "        train_images, val_images, train_labels, val_labels = train_test_split(data, \n",
    "                                                                labels, \n",
    "                                                                test_size=0.3, \n",
    "                                                                random_state=42)\n",
    "        \n",
    "        clf = LinearRegression()\n",
    "        \n",
    "        train_mu = np.mean(train_images)\n",
    "        train_std = np.std(train_images)\n",
    "        \n",
    "        train_images = normalize(train_images, train_mu, train_std)\n",
    "        val_images = normalize(val_images, train_mu, train_std)\n",
    "        \n",
    "        clf.fit(train_images, train_labels)\n",
    "        val_predictions = clf.predict(val_images)\n",
    "        mse = mean_squared_error(val_labels, val_predictions)\n",
    "        mae = mean_absolute_error(val_labels, val_predictions)\n",
    "        r2 = r2_score(val_labels, val_predictions)  \n",
    "        \n",
    "        return mse, mae, r2        \n",
    "        \n",
    "    else:\n",
    "        train_images, val_images, train_labels, val_labels = train_test_split(data, \n",
    "                                                                labels, \n",
    "                                                                test_size=0.3, \n",
    "                                                                random_state=42,\n",
    "                                                                stratify = labels)   \n",
    "    \n",
    "        clf = LogisticRegression(multi_class='multinomial')\n",
    "        \n",
    "        train_mu = np.mean(train_images)\n",
    "        train_std = np.std(train_images)\n",
    "        \n",
    "        train_images = normalize(train_images, train_mu, train_std)\n",
    "        val_images = normalize(val_images, train_mu, train_std)    \n",
    "        \n",
    "        clf.fit(train_images, train_labels)\n",
    "        val_predictions = clf.predict(val_images)\n",
    "        acc = accuracy_score(val_labels, val_predictions)        \n",
    "        bac = balanced_accuracy_score(val_labels, val_predictions)\n",
    "        f1 = f1_score(val_labels, val_predictions, average='macro')   \n",
    "        \n",
    "        return acc, bac, f1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978c3cd0",
   "metadata": {},
   "source": [
    "## Plastic flakes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06f64bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset info...\n",
      "The shape of the original imagery: (11, 112128, 224)\n",
      "The shape of the original labels: (11, 112128)\n",
      "The shape of the vertically stacked images: (1233408, 224)\n",
      "The shape of the vertically stacked images: (1233408,)\n"
     ]
    }
   ],
   "source": [
    "# stacks all images vertically\n",
    "\n",
    "# load data\n",
    "\n",
    "if do_plastic_flakes:\n",
    "    \n",
    "    hyper, gt = load_datasets(\n",
    "        'PF')\n",
    "    \n",
    "    hyper, gt = np.array(hyper), np.array(gt)\n",
    "    \n",
    "    hyper_multiple = np.empty([hyper.shape[0]*hyper.shape[1], hyper.shape[-1]])\n",
    "    gt_multiple = np.empty([gt.shape[0]*gt.shape[1]])\n",
    "    \n",
    "    print('\\nDataset info...')\n",
    "    print('The shape of the original imagery:', hyper.shape)\n",
    "    print('The shape of the original labels:', gt.shape)\n",
    "    \n",
    "    for i in range(hyper.shape[0]):\n",
    "        hyper_multiple[i*hyper.shape[1]:(i+1)*hyper.shape[1] , :] = hyper[i, :, :]\n",
    "        gt_multiple[i*hyper.shape[1]:(i+1)*hyper.shape[1]] = gt[i, :]\n",
    "\n",
    "    print('The shape of the vertically stacked images:', hyper_multiple.shape)\n",
    "    print('The shape of the vertically stacked images:', gt_multiple.shape)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bf8dd6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"    \\nif do_plastic_flakes:\\n    \\n    num_runs = 25\\n    \\n    # randomly sample hyper_multiple for 5% of the pixels\\n    indices = np.random.randint(0, hyper_multiple.shape[0], int(hyper_multiple.shape[0]*0.05))\\n    hyper_multiple = hyper_multiple[indices, :]\\n    print('The shape of the sub-sampled vertically stacked images:', hyper_multiple.shape)\\n    \\n    correlations = []\\n    for i in range(num_runs):\\n        correlations.append(calculate_correlations(hyper_multiple, num_bands_originally=hyper_multiple.shape[-1], num_bands_kept=30))\\n    print(f'\\nCorrelation reward for random 30 bands, x{num_runs} runs:', np.mean(correlations))\\n    \\n    mis = []\\n    for i in range(num_runs):\\n        mis.append(calculate_mutual_infos(hyper_multiple, num_bands_originally=hyper_multiple.shape[-1], num_bands_kept=30))\\n    print(f'Normalized mutual information reward for random 30 bands, x{num_runs} runs:', np.mean(mis))\\n    \\n    # plot rewards\\n    a_string = ['pearson correlation (cumulative avg)'] * len(correlations)    \\n    b_string = ['normalized mutual information (cumulative avg)'] * len(mis)\\n    strings = a_string + b_string\\n    pd_df = pd.DataFrame([correlations+mis, strings]).T\\n    pd_df[0] = pd_df[0].astype(float, copy=True)\\n    pd_df.columns = ['Reward Metric']\\n    sns.histplot(data=pd_df, bins=15, x=0, hue=1, kde=True)\\n    plt.title(f'Test', fontsize=17)\\n    #plt.xlim([0,1])\\n    plt.show()\\n    plt.figure()\\n    \""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rewards\n",
    "\"\"\"    \n",
    "if do_plastic_flakes:\n",
    "    \n",
    "    num_runs = 25\n",
    "    \n",
    "    # randomly sample hyper_multiple for 5% of the pixels\n",
    "    indices = np.random.randint(0, hyper_multiple.shape[0], int(hyper_multiple.shape[0]*0.05))\n",
    "    hyper_multiple = hyper_multiple[indices, :]\n",
    "    print('The shape of the sub-sampled vertically stacked images:', hyper_multiple.shape)\n",
    "    \n",
    "    correlations = []\n",
    "    for i in range(num_runs):\n",
    "        correlations.append(calculate_correlations(hyper_multiple, num_bands_originally=hyper_multiple.shape[-1], num_bands_kept=30))\n",
    "    print(f'\\nCorrelation reward for random 30 bands, x{num_runs} runs:', np.mean(correlations))\n",
    "    \n",
    "    mis = []\n",
    "    for i in range(num_runs):\n",
    "        mis.append(calculate_mutual_infos(hyper_multiple, num_bands_originally=hyper_multiple.shape[-1], num_bands_kept=30))\n",
    "    print(f'Normalized mutual information reward for random 30 bands, x{num_runs} runs:', np.mean(mis))\n",
    "    \n",
    "    # plot rewards\n",
    "    a_string = ['pearson correlation (cumulative avg)'] * len(correlations)    \n",
    "    b_string = ['normalized mutual information (cumulative avg)'] * len(mis)\n",
    "    strings = a_string + b_string\n",
    "    pd_df = pd.DataFrame([correlations+mis, strings]).T\n",
    "    pd_df[0] = pd_df[0].astype(float, copy=True)\n",
    "    pd_df.columns = ['Reward Metric']\n",
    "    sns.histplot(data=pd_df, bins=15, x=0, hue=1, kde=True)\n",
    "    plt.title(f'Test', fontsize=17)\n",
    "    #plt.xlim([0,1])\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "394ce5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model performance on rescaled data (ints) with all bands...\n",
      "Validation Accuracy: 0.9713617040826531\n",
      "Validation Balanced Accuracy: 0.9548121247085622\n",
      "Validation Macro Averaged F1 Score: 0.9530316150340309\n",
      "\n",
      "Baseline model performance on rescaled data (ints) with 30 band random subset...\n",
      "Validation Accuracy: 0.958792418972567\n",
      "Validation Balanced Accuracy: 0.9316408124709102\n",
      "Validation Macro Averaged F1 Score: 0.9315067333001887\n"
     ]
    }
   ],
   "source": [
    "# baseline models\n",
    "\n",
    "data_path = '../data/plastic_flakes/'\n",
    "hsi_paths = glob.glob(data_path + 'hyperspectral_imagery/*.npy')\n",
    "gt_paths = []\n",
    "for i in range(len(hsi_paths)):\n",
    "     num = hsi_paths[i].split('.')[2].split('/')[-1]\n",
    "     gt_paths.append(data_path + f'gt_labels/{num}.npy')\n",
    "\n",
    "#print(hsi_paths)\n",
    "#print(gt_paths)\n",
    "\n",
    "# model with all bands included\n",
    "\n",
    "accs, bacs, f1s = [], [], []\n",
    "for i in range(0, len(hsi_paths)):\n",
    "\n",
    "    acc, bac, f1 = baseline_supervised_pass(hsi_paths[i], gt_paths[i], 'PF')\n",
    "    accs.append(acc)\n",
    "    bacs.append(bac)\n",
    "    f1s.append(f1)\n",
    "\n",
    "print(f'Baseline model performance on rescaled data (ints) with all bands...')\n",
    "print(f'Validation Accuracy: {np.mean(accs)}')\n",
    "print(f'Validation Balanced Accuracy: {np.mean(bacs)}')\n",
    "print(f'Validation Macro Averaged F1 Score: {np.mean(f1s)}')\n",
    "\n",
    "# model with random bands\n",
    "\n",
    "accs, bacs, f1s = [], [], []\n",
    "for i in range(0, len(hsi_paths)):\n",
    "\n",
    "    acc, bac, f1 = baseline_supervised_pass(hsi_paths[i], gt_paths[i], 'PF', True, 30)\n",
    "    accs.append(acc)\n",
    "    bacs.append(bac)\n",
    "    f1s.append(f1)\n",
    "\n",
    "print(f'\\nBaseline model performance on rescaled data (ints) with {30} band random subset...')\n",
    "print(f'Validation Accuracy: {np.mean(accs)}')\n",
    "print(f'Validation Balanced Accuracy: {np.mean(bacs)}')\n",
    "print(f'Validation Macro Averaged F1 Score: {np.mean(f1s)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b213af",
   "metadata": {},
   "source": [
    "## Salient objects dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5364f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset info...\n",
      "The shape of the original imagery: (60, 786432, 81)\n",
      "The shape of the original labels: (60, 786432)\n",
      "\n",
      "Dataset info...\n",
      "The shape of the vertically stacked images: (47185920, 81)\n",
      "The shape of the vertically stacked images: (47185920,)\n",
      "The shape of the sub-sampled vertically stacked images: (47185, 81)\n"
     ]
    }
   ],
   "source": [
    "# stacks all images vertically\n",
    "\n",
    "# load data\n",
    "\n",
    "if do_salient_objects:\n",
    "    \n",
    "    hyper, gt = load_datasets(\n",
    "        'SO')\n",
    "    \n",
    "    hyper, gt = np.array(hyper), np.array(gt)\n",
    "    \n",
    "    hyper_multiple = np.empty([hyper.shape[0]*hyper.shape[1], hyper.shape[-1]])\n",
    "    gt_multiple = np.empty([gt.shape[0]*gt.shape[1]])\n",
    "    \n",
    "    print('\\nDataset info...')\n",
    "    print('The shape of the original imagery:', hyper.shape)\n",
    "    print('The shape of the original labels:', gt.shape)\n",
    "    \n",
    "    for i in range(hyper.shape[0]):\n",
    "        hyper_multiple[i*hyper.shape[1]:(i+1)*hyper.shape[1] , :] = hyper[i, :, :]\n",
    "        gt_multiple[i*hyper.shape[1]:(i+1)*hyper.shape[1]] = gt[i, :]\n",
    "\n",
    "    print('\\nDataset info...')\n",
    "    print('The shape of the vertically stacked images:', hyper_multiple.shape)\n",
    "    print('The shape of the vertically stacked images:', gt_multiple.shape)    \n",
    "\n",
    "    # randomly sample hyper_multiple for .1% of the pixels\n",
    "    indices = np.random.randint(0, hyper_multiple.shape[0], int(hyper_multiple.shape[0]*0.001))\n",
    "    hyper_multiple = hyper_multiple[indices, :]\n",
    "    print('The shape of the sub-sampled vertically stacked images:', hyper_multiple.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20d99755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"    \\nif do_salient_objects:\\n    \\n    num_runs = 25\\n    \\n    correlations = []\\n    for i in range(num_runs):\\n        correlations.append(calculate_correlations(hyper_multiple, num_bands_originally=hyper_multiple.shape[-1], num_bands_kept=30))\\n    print(f'\\nCorrelation reward for random 30 bands, x{num_runs} runs:', np.mean(correlations))\\n    \\n    mis = []\\n    for i in range(num_runs):\\n        mis.append(calculate_mutual_infos(hyper_multiple, num_bands_originally=hyper_multiple.shape[-1], num_bands_kept=30))\\n    print(f'Normalized mutual information reward for random 30 bands, x{num_runs} runs:', np.mean(mis))\\n    \\n    # plot rewards\\n    a_string = ['pearson correlation (cumulative avg)'] * len(correlations)    \\n    b_string = ['normalized mutual information (cumulative avg)'] * len(mis)\\n    strings = a_string + b_string\\n    pd_df = pd.DataFrame([correlations+mis, strings]).T\\n    pd_df[0] = pd_df[0].astype(float, copy=True)\\n    pd_df.columns = ['Reward Metric']\\n    sns.histplot(data=pd_df, bins=20, x=0, hue=1, kde=True)\\n    plt.title(f'Test', fontsize=17)\\n    #plt.xlim([0,1])\\n    plt.show()\\n    plt.figure()\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rewards\n",
    "\"\"\"    \n",
    "if do_salient_objects:\n",
    "    \n",
    "    num_runs = 25\n",
    "    \n",
    "    correlations = []\n",
    "    for i in range(num_runs):\n",
    "        correlations.append(calculate_correlations(hyper_multiple, num_bands_originally=hyper_multiple.shape[-1], num_bands_kept=30))\n",
    "    print(f'\\nCorrelation reward for random 30 bands, x{num_runs} runs:', np.mean(correlations))\n",
    "    \n",
    "    mis = []\n",
    "    for i in range(num_runs):\n",
    "        mis.append(calculate_mutual_infos(hyper_multiple, num_bands_originally=hyper_multiple.shape[-1], num_bands_kept=30))\n",
    "    print(f'Normalized mutual information reward for random 30 bands, x{num_runs} runs:', np.mean(mis))\n",
    "    \n",
    "    # plot rewards\n",
    "    a_string = ['pearson correlation (cumulative avg)'] * len(correlations)    \n",
    "    b_string = ['normalized mutual information (cumulative avg)'] * len(mis)\n",
    "    strings = a_string + b_string\n",
    "    pd_df = pd.DataFrame([correlations+mis, strings]).T\n",
    "    pd_df[0] = pd_df[0].astype(float, copy=True)\n",
    "    pd_df.columns = ['Reward Metric']\n",
    "    sns.histplot(data=pd_df, bins=20, x=0, hue=1, kde=True)\n",
    "    plt.title(f'Test', fontsize=17)\n",
    "    #plt.xlim([0,1])\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e62ae94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model performance on rescaled data (ints) with all bands...\n",
      "Validation Accuracy: 0.9348171067689569\n",
      "Validation Balanced Accuracy: 0.6789592114043078\n",
      "Validation Macro Averaged F1 Score: 0.7062977883143245\n",
      "\n",
      "Baseline model performance on rescaled data (ints) with 30 band random subset...\n",
      "Validation Accuracy: 0.924376015484819\n",
      "Validation Balanced Accuracy: 0.6157260357618256\n",
      "Validation Macro Averaged F1 Score: 0.6314979792421563\n"
     ]
    }
   ],
   "source": [
    "# baseline models\n",
    "\n",
    "data_path = '../data/salient_objects/'\n",
    "hsi_paths = glob.glob(data_path + 'hyperspectral_imagery/*.npy')\n",
    "gt_paths = []\n",
    "for i in range(len(hsi_paths)):\n",
    "     num = hsi_paths[i].split('.')[2].split('/')[-1]\n",
    "     gt_paths.append(data_path + f'gt_labels/{num}.npy')\n",
    "\n",
    "#print(hsi_paths)\n",
    "#print(gt_paths)\n",
    "\n",
    "# model with all bands included\n",
    "\n",
    "accs, bacs, f1s = [], [], []\n",
    "for i in range(0, len(hsi_paths)):\n",
    "\n",
    "    acc, bac, f1 = baseline_supervised_pass(hsi_paths[i], gt_paths[i], 'SO')\n",
    "    accs.append(acc)\n",
    "    bacs.append(bac)\n",
    "    f1s.append(f1)\n",
    "\n",
    "print(f'Baseline model performance on rescaled data (ints) with all bands...')\n",
    "print(f'Validation Accuracy: {np.mean(accs)}')\n",
    "print(f'Validation Balanced Accuracy: {np.mean(bacs)}')\n",
    "print(f'Validation Macro Averaged F1 Score: {np.mean(f1s)}')\n",
    "\n",
    "# model with random bands\n",
    "\n",
    "accs, bacs, f1s = [], [], []\n",
    "for i in range(0, len(hsi_paths)):\n",
    "\n",
    "    acc, bac, f1 = baseline_supervised_pass(hsi_paths[i], gt_paths[i], 'SO', True, 30)\n",
    "    accs.append(acc)\n",
    "    bacs.append(bac)\n",
    "    f1s.append(f1)\n",
    "\n",
    "print(f'\\nBaseline model performance on rescaled data (ints) with {30} band random subset...')\n",
    "print(f'Validation Accuracy: {np.mean(accs)}')\n",
    "print(f'Validation Balanced Accuracy: {np.mean(bacs)}')\n",
    "print(f'Validation Macro Averaged F1 Score: {np.mean(f1s)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset info...\n",
      "The shape of the original imagery: (679, 125)\n",
      "The shape of the original labels: (679,)\n",
      "\n",
      "Correlation: 0.957538007779195\n",
      "Normalized mutual information: 0.6677776488857733\n",
      "\n",
      "Model performance with RL agent selected bands...\n",
      "Validation MSE: 2.1394362621755927\n",
      "Validation MAE: 1.1637981283482837\n",
      "Validation r2: 0.848383500398763\n"
     ]
    }
   ],
   "source": [
    "## Plastic flakes dataset\n",
    "# stacks all images vertically\n",
    "\n",
    "# load data\n",
    "\n",
    "if do_plastic_flakes:\n",
    "    \n",
    "    hyper, gt = load_datasets(\n",
    "        'PF')\n",
    "    \n",
    "    hyper, gt = np.array(hyper), np.array(gt)\n",
    "    \n",
    "    hyper_multiple = np.empty([hyper.shape[0]*hyper.shape[1], hyper.shape[-1]])\n",
    "    gt_multiple = np.empty([gt.shape[0]*gt.shape[1]])\n",
    "    \n",
    "    print('\\nDataset info...')\n",
    "    print('The shape of the original imagery:', hyper.shape)\n",
    "    print('The shape of the original labels:', gt.shape)\n",
    "    \n",
    "    for i in range(hyper.shape[0]):\n",
    "        hyper_multiple[i*hyper.shape[1]:(i+1)*hyper.shape[1] , :] = hyper[i, :, :]\n",
    "        gt_multiple[i*hyper.shape[1]:(i+1)*hyper.shape[1]] = gt[i, :]\n",
    "\n",
    "    print('The shape of the vertically stacked images:', hyper_multiple.shape)\n",
    "    print('The shape of the vertically stacked images:', gt_multiple.shape)    \n",
    "\n",
    "# rewards\n",
    "    \n",
    "if do_plastic_flakes:\n",
    "    correlation = calculate_correlations(hyper, selected_bands)\n",
    "    print(f'\\nCorrelation:', correlation)\n",
    "    mi = calculate_mutual_infos(hyper, selected_bands)\n",
    "    print(f'Normalized mutual information:', mi)\n",
    "\n",
    "if do_plastic_flakes and do_supervised_modeling:\n",
    "\n",
    "    # baseline models\n",
    "    \n",
    "    data_path = '../plastic_flakes/'\n",
    "    hsi_paths = glob.glob(data_path + 'hyperspectral_imagery/*.npy')\n",
    "    gt_paths = []\n",
    "    for i in range(len(hsi_paths)):\n",
    "         num = hsi_paths[i].split('.')[2].split('/')[-1]\n",
    "         gt_paths.append(data_path + f'gt_labels/{num}.npy')\n",
    "    \n",
    "    \n",
    "    accs, bacs, f1s = [], [], []\n",
    "    for i in range(0, len(hsi_paths)):\n",
    "    \n",
    "        acc, bac, f1 = baseline_supervised_pass(hsi_paths[i], gt_paths[i], 'PF', selected_bands)\n",
    "        accs.append(acc)\n",
    "        bacs.append(bac)\n",
    "        f1s.append(f1)\n",
    "    \n",
    "    print(f'\\nModel performance with RL agent selected bands...')\n",
    "    print(f'Validation Accuracy: {np.mean(accs)}')\n",
    "    print(f'Validation Balanced Accuracy: {np.mean(bacs)}')\n",
    "    print(f'Validation Macro Averaged F1 Score: {np.mean(f1s)}')\n",
    "\n",
    "## Salient objects dataset\n",
    "# stacks all images vertically\n",
    "\n",
    "# load data\n",
    "\n",
    "if do_salient_objects:\n",
    "    \n",
    "    hyper, gt = load_datasets(\n",
    "        'SO')\n",
    "    \n",
    "    hyper, gt = np.array(hyper), np.array(gt)\n",
    "    \n",
    "    hyper_multiple = np.empty([hyper.shape[0]*hyper.shape[1], hyper.shape[-1]])\n",
    "    gt_multiple = np.empty([gt.shape[0]*gt.shape[1]])\n",
    "    \n",
    "    print('\\nDataset info...')\n",
    "    print('The shape of the original imagery:', hyper.shape)\n",
    "    print('The shape of the original labels:', gt.shape)\n",
    "    \n",
    "    for i in range(hyper.shape[0]):\n",
    "        hyper_multiple[i*hyper.shape[1]:(i+1)*hyper.shape[1] , :] = hyper[i, :, :]\n",
    "        gt_multiple[i*hyper.shape[1]:(i+1)*hyper.shape[1]] = gt[i, :]\n",
    "\n",
    "    print('\\nDataset info...')\n",
    "    print('The shape of the vertically stacked images:', hyper_multiple.shape)\n",
    "    print('The shape of the vertically stacked images:', gt_multiple.shape)    \n",
    "\n",
    "# rewards\n",
    "    \n",
    "if do_salient_objects:\n",
    "    correlation = calculate_correlations(hyper, selected_bands)\n",
    "    print(f'\\nCorrelation:', correlation)\n",
    "    mi = calculate_mutual_infos(hyper, selected_bands)\n",
    "    print(f'Normalized mutual information:', mi)\n",
    "\n",
    "\n",
    "if do_salient_objects and do_supervised_modeling:\n",
    "    # baseline models\n",
    "    \n",
    "    data_path = '../salient_objects/'\n",
    "    hsi_paths = glob.glob(data_path + 'hyperspectral_imagery/*.npy')\n",
    "    gt_paths = []\n",
    "    for i in range(len(hsi_paths)):\n",
    "         num = hsi_paths[i].split('.')[2].split('/')[-1]\n",
    "         gt_paths.append(data_path + f'gt_labels/{num}.npy')\n",
    "    \n",
    "    \n",
    "    #print(hsi_paths)\n",
    "    #print(gt_paths)\n",
    "    \n",
    "    accs, bacs, f1s = [], [], []\n",
    "    for i in range(0, len(hsi_paths)):\n",
    "    \n",
    "        acc, bac, f1 = baseline_supervised_pass(hsi_paths[i], gt_paths[i], 'SO', selected_bands)\n",
    "        accs.append(acc)\n",
    "        bacs.append(bac)\n",
    "        f1s.append(f1)\n",
    "    \n",
    "    print(f'\\nModel performance with RL agent selected bands...')\n",
    "    print(f'Validation Accuracy: {np.mean(accs)}')\n",
    "    print(f'Validation Balanced Accuracy: {np.mean(bacs)}')\n",
    "    print(f'Validation Macro Averaged F1 Score: {np.mean(f1s)}')\n",
    "\n",
    "## Indian Pines dataset\n",
    "# load data\n",
    "\n",
    "if do_indian_pines:\n",
    "    \n",
    "    hyper, gt = load_datasets(\n",
    "        'IN')\n",
    "    \n",
    "    print('\\nDataset info...')\n",
    "    print('The shape of the original imagery:', hyper.shape)\n",
    "    print('The shape of the original labels:', gt.shape)\n",
    "    \n",
    "# rewards\n",
    "    \n",
    "if do_indian_pines:\n",
    "    correlation = calculate_correlations(hyper, selected_bands)\n",
    "    print(f'\\nCorrelation:', correlation)\n",
    "    mi = calculate_mutual_infos(hyper, selected_bands)\n",
    "    print(f'Normalized mutual information:', mi)\n",
    "\n",
    "if do_indian_pines and do_supervised_modeling:\n",
    "\n",
    "\n",
    "    # baseline models\n",
    "    \n",
    "    data_fpath = '../indian_pines/hyperspectral_imagery/indian_pines_corrected.npy'\n",
    "    labels_fpath = '../indian_pines/gt_labels/indian_pines_gt.npy'\n",
    "    \n",
    "    # model with all bands included\n",
    "    print(f'\\nModel performance with RL agent selected bands...')\n",
    "    acc, bac, f1 = baseline_supervised_pass(data_fpath, labels_fpath, 'IN', selected_bands)\n",
    "    print(f'Validation Accuracy: {acc}')\n",
    "    print(f'Validation Balanced Accuracy: {bac}')\n",
    "    print(f'Validation Macro Averaged F1 Score: {f1}')\n",
    "    ## Soil moisture dataset\n",
    "    # load data\n",
    "\n",
    "if do_soil_moisture:\n",
    "    \n",
    "    hyper, gt = load_datasets(\n",
    "        'SM')\n",
    "    \n",
    "    print('\\nDataset info...')\n",
    "    print('The shape of the original imagery:', hyper.shape)\n",
    "    print('The shape of the original labels:', gt.shape)\n",
    "    \n",
    "# rewards\n",
    "    \n",
    "if do_soil_moisture:    \n",
    "    correlation = calculate_correlations(hyper, selected_bands)\n",
    "    print(f'\\nCorrelation:', correlation)\n",
    "    mi = calculate_mutual_infos(hyper, selected_bands)\n",
    "    print(f'Normalized mutual information:', mi)\n",
    "\n",
    "    \n",
    "if do_soil_moisture and do_supervised_modeling:\n",
    "\n",
    "    # baseline models \n",
    "    \n",
    "    data_fpath = '../soil_moisture/hyperspectral_imagery/soil_moisture_hyper.npy'\n",
    "    labels_fpath = '../soil_moisture/gt_labels/soil_moisture_gt.npy'\n",
    "    \n",
    "    print(f'\\nModel performance with RL agent selected bands...')\n",
    "    \n",
    "    mse, mae, r2 = baseline_supervised_pass(data_fpath, labels_fpath, 'SM', selected_bands)\n",
    "    print(f'Validation MSE: {mse}')\n",
    "    print(f'Validation MAE: {mae}')\n",
    "    print(f'Validation r2: {r2}')\n",
    "\n",
    "## Foods dataset\n",
    "\n",
    "# load data\n",
    "\n",
    "if do_foods:\n",
    "    \n",
    "    hyper, gt = load_datasets(\n",
    "        'Foods')\n",
    "\n",
    "    hyper, gt = hyper[0], gt[0]\n",
    "    \n",
    "    print('\\nDataset info...')\n",
    "    print('The shape of the original imagery:', hyper.shape)\n",
    "    print('The shape of the original labels:', gt.shape)\n",
    "    \n",
    "# rewards\n",
    "    \n",
    "if do_foods:\n",
    "    correlation = calculate_correlations(hyper, selected_bands)\n",
    "    print(f'\\nCorrelation:', correlation)\n",
    "    mi = calculate_mutual_infos(hyper, selected_bands)\n",
    "    print(f'Normalized mutual information:', mi)\n",
    "\n",
    "if do_foods and do_supervised_modeling:\n",
    "\n",
    "\n",
    "    # baseline models\n",
    "    \n",
    "    data_fpath = '../foods/hyperspectral_imagery/foods_hyper.npy'\n",
    "    labels_fpath = '../foods/gt_labels/foods_gt.npy'\n",
    "    \n",
    "    # model with all bands included\n",
    "    print(f'\\nModel performance with RL agent selected bands...')\n",
    "    \n",
    "    # model with random bands\n",
    "    print(f'\\nBaseline model performance on rescaled data (ints) with {30} band random subset...')\n",
    "    acc, bac, f1 = baseline_supervised_pass(data_fpath, labels_fpath, 'Foods', selected_bands)\n",
    "    print(f'Validation Accuracy: {acc}')\n",
    "    print(f'Validation Balanced Accuracy: {bac}')\n",
    "    print(f'Validation Macro Averaged F1 Score: {f1}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indian Pines dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset info...\n",
      "The shape of the original imagery: (10249, 200)\n",
      "The shape of the original labels: (10249,)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "if do_indian_pines:\n",
    "    \n",
    "    hyper, gt = load_datasets(\n",
    "        'IN')\n",
    "    \n",
    "    print('\\nDataset info...')\n",
    "    print('The shape of the original imagery:', hyper.shape)\n",
    "    print('The shape of the original labels:', gt.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"    \\nif do_indian_pines:\\n    num_runs = 25\\n    \\n    correlations = []\\n    for i in range(num_runs):\\n        correlations.append(calculate_correlations(hyper, num_bands_originally=hyper.shape[-1], num_bands_kept=30))\\n    print(f'\\nCorrelation reward for random 30 bands, x{num_runs} runs:', np.mean(correlations))\\n    \\n    mis = []\\n    for i in range(num_runs):\\n        mis.append(calculate_mutual_infos(hyper, num_bands_originally=hyper.shape[-1], num_bands_kept=30))\\n    print(f'Normalized mutual information reward for random 30 bands, x{num_runs} runs:', np.mean(mis))\\n    \\n    # plot rewards\\n    a_string = ['pearson correlation (cumulative avg)'] * len(correlations)    \\n    b_string = ['normalized mutual information (cumulative avg)'] * len(mis)\\n    strings = a_string + b_string\\n    pd_df = pd.DataFrame([correlations+mis, strings]).T\\n    pd_df[0] = pd_df[0].astype(float, copy=True)\\n    pd_df.columns = ['Reward Metric']\\n\\n    sns.histplot(data=pd_df, bins=20, x=0, hue=1, kde=True)\\n    plt.title(f'Test', fontsize=17)\\n    #plt.xlim([0,1])\\n    plt.show()\\n    plt.figure()\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rewards\n",
    "\"\"\"    \n",
    "if do_indian_pines:\n",
    "    num_runs = 25\n",
    "    \n",
    "    correlations = []\n",
    "    for i in range(num_runs):\n",
    "        correlations.append(calculate_correlations(hyper, num_bands_originally=hyper.shape[-1], num_bands_kept=30))\n",
    "    print(f'\\nCorrelation reward for random 30 bands, x{num_runs} runs:', np.mean(correlations))\n",
    "    \n",
    "    mis = []\n",
    "    for i in range(num_runs):\n",
    "        mis.append(calculate_mutual_infos(hyper, num_bands_originally=hyper.shape[-1], num_bands_kept=30))\n",
    "    print(f'Normalized mutual information reward for random 30 bands, x{num_runs} runs:', np.mean(mis))\n",
    "    \n",
    "    # plot rewards\n",
    "    a_string = ['pearson correlation (cumulative avg)'] * len(correlations)    \n",
    "    b_string = ['normalized mutual information (cumulative avg)'] * len(mis)\n",
    "    strings = a_string + b_string\n",
    "    pd_df = pd.DataFrame([correlations+mis, strings]).T\n",
    "    pd_df[0] = pd_df[0].astype(float, copy=True)\n",
    "    pd_df.columns = ['Reward Metric']\n",
    "\n",
    "    sns.histplot(data=pd_df, bins=20, x=0, hue=1, kde=True)\n",
    "    plt.title(f'Test', fontsize=17)\n",
    "    #plt.xlim([0,1])\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model performance on rescaled data (ints) with all bands...\n",
      "Validation Accuracy: 0.26504065040650404\n",
      "Validation Balanced Accuracy: 0.08574691943516832\n",
      "Validation Macro Averaged F1 Score: 0.06477141245017229\n",
      "\n",
      "Baseline model performance on rescaled data (ints) with 30 band random subset...\n",
      "Validation Accuracy: 0.24813008130081302\n",
      "Validation Balanced Accuracy: 0.07261958833153297\n",
      "Validation Macro Averaged F1 Score: 0.04460649329063645\n"
     ]
    }
   ],
   "source": [
    "# baseline models\n",
    "\n",
    "data_fpath = '../data/indian_pines/hyperspectral_imagery/indian_pines_corrected.npy'\n",
    "labels_fpath = '../data/indian_pines/gt_labels/indian_pines_gt.npy'\n",
    "\n",
    "# model with all bands included\n",
    "print(f'Baseline model performance on rescaled data (ints) with all bands...')\n",
    "acc, bac, f1 = baseline_supervised_pass(data_fpath, labels_fpath, 'IN')\n",
    "print(f'Validation Accuracy: {acc}')\n",
    "print(f'Validation Balanced Accuracy: {bac}')\n",
    "print(f'Validation Macro Averaged F1 Score: {f1}')\n",
    "\n",
    "# model with random bands\n",
    "print(f'\\nBaseline model performance on rescaled data (ints) with {30} band random subset...')\n",
    "acc, bac, f1 = baseline_supervised_pass(data_fpath, labels_fpath, 'IN', True, 30)\n",
    "print(f'Validation Accuracy: {acc}')\n",
    "print(f'Validation Balanced Accuracy: {bac}')\n",
    "print(f'Validation Macro Averaged F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soil moisture dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ca19147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset info...\n",
      "The shape of the original imagery: (679, 125)\n",
      "The shape of the original labels: (679,)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "if do_soil_moisture:\n",
    "    \n",
    "    hyper, gt = load_datasets(\n",
    "        'SM')\n",
    "    \n",
    "    print('\\nDataset info...')\n",
    "    print('The shape of the original imagery:', hyper.shape)\n",
    "    print('The shape of the original labels:', gt.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nif do_soil_moisture:\\n    num_runs = 25\\n    \\n    correlations = []\\n    for i in range(num_runs):\\n        correlations.append(calculate_correlations(hyper, num_bands_originally=hyper.shape[-1], num_bands_kept=30))\\n    print(f'\\nCorrelation reward for random 30 bands, x{num_runs} runs:', np.mean(correlations))\\n    \\n    mis = []\\n    for i in range(num_runs):\\n        mis.append(calculate_mutual_infos(hyper, num_bands_originally=hyper.shape[-1], num_bands_kept=30))\\n    print(f'Normalized mutual information reward for random 30 bands, x{num_runs} runs:', np.mean(mis))\\n    \\n    # plot rewards\\n    a_string = ['pearson correlation (cumulative avg)'] * len(correlations)    \\n    b_string = ['normalized mutual information (cumulative avg)'] * len(mis)\\n    strings = a_string + b_string\\n    pd_df = pd.DataFrame([correlations+mis, strings]).T\\n    pd_df[0] = pd_df[0].astype(float, copy=True)\\n    pd_df.columns = ['Reward Metric']\\n    sns.histplot(data=pd_df, binwidth=0.008, x=0, hue=1, kde=True)\\n    plt.title(f'Test', fontsize=17)\\n    #plt.xlim([0,1])\\n    plt.show()\\n    plt.figure()\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rewards\n",
    "\"\"\"\n",
    "if do_soil_moisture:\n",
    "    num_runs = 25\n",
    "    \n",
    "    correlations = []\n",
    "    for i in range(num_runs):\n",
    "        correlations.append(calculate_correlations(hyper, num_bands_originally=hyper.shape[-1], num_bands_kept=30))\n",
    "    print(f'\\nCorrelation reward for random 30 bands, x{num_runs} runs:', np.mean(correlations))\n",
    "    \n",
    "    mis = []\n",
    "    for i in range(num_runs):\n",
    "        mis.append(calculate_mutual_infos(hyper, num_bands_originally=hyper.shape[-1], num_bands_kept=30))\n",
    "    print(f'Normalized mutual information reward for random 30 bands, x{num_runs} runs:', np.mean(mis))\n",
    "    \n",
    "    # plot rewards\n",
    "    a_string = ['pearson correlation (cumulative avg)'] * len(correlations)    \n",
    "    b_string = ['normalized mutual information (cumulative avg)'] * len(mis)\n",
    "    strings = a_string + b_string\n",
    "    pd_df = pd.DataFrame([correlations+mis, strings]).T\n",
    "    pd_df[0] = pd_df[0].astype(float, copy=True)\n",
    "    pd_df.columns = ['Reward Metric']\n",
    "    sns.histplot(data=pd_df, binwidth=0.008, x=0, hue=1, kde=True)\n",
    "    plt.title(f'Test', fontsize=17)\n",
    "    #plt.xlim([0,1])\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model performance on rescaled data (ints) with all bands...\n",
      "Validation MSE: 2.207357810591\n",
      "Validation MAE: 1.1874092003943846\n",
      "Validation r2: 0.8435700700571795\n",
      "\n",
      "Baseline model performance on rescaled data (ints) with 30 band random subset...\n",
      "Validation MSE: 3.2095624547610444\n",
      "Validation MAE: 1.353479616841915\n",
      "Validation r2: 0.7725463322999038\n"
     ]
    }
   ],
   "source": [
    "# baseline models \n",
    "\n",
    "data_fpath = '../data/soil_moisture/hyperspectral_imagery/soil_moisture_hyper.npy'\n",
    "labels_fpath = '../data/soil_moisture/gt_labels/soil_moisture_gt.npy'\n",
    "\n",
    "# model with all bands included\n",
    "print(f'Baseline model performance on rescaled data (ints) with all bands...')\n",
    "mse, mae, r2  = baseline_supervised_pass(data_fpath, labels_fpath, 'SM')\n",
    "print(f'Validation MSE: {mse}')\n",
    "print(f'Validation MAE: {mae}')\n",
    "print(f'Validation r2: {r2}')\n",
    "\n",
    "# model with random bands\n",
    "print(f'\\nBaseline model performance on rescaled data (ints) with {30} band random subset...')\n",
    "\n",
    "mse, mae, r2 = baseline_supervised_pass(data_fpath, labels_fpath, 'SM', True, 30)\n",
    "print(f'Validation MSE: {mse}')\n",
    "print(f'Validation MAE: {mae}')\n",
    "print(f'Validation r2: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foods dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset info...\n",
      "The shape of the original imagery: (2400, 96)\n",
      "The shape of the original labels: (2400,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"    \\nif do_foods:\\n    num_runs = 25\\n    \\n    correlations = []\\n    for i in range(num_runs):\\n        correlations.append(calculate_correlations(hyper, num_bands_originally=hyper.shape[-1], num_bands_kept=30))\\n    print(f'\\nCorrelation reward for random 30 bands, x{num_runs} runs:', np.mean(correlations))\\n    \\n    mis = []\\n    for i in range(num_runs):\\n        mis.append(calculate_mutual_infos(hyper, num_bands_originally=hyper.shape[-1], num_bands_kept=30))\\n    print(f'Normalized mutual information reward for random 30 bands, x{num_runs} runs:', np.mean(mis))\\n    \\n    # plot rewards\\n    a_string = ['pearson correlation (cumulative avg)'] * len(correlations)    \\n    b_string = ['normalized mutual information (cumulative avg)'] * len(mis)\\n    strings = a_string + b_string\\n    pd_df = pd.DataFrame([correlations+mis, strings]).T\\n    pd_df[0] = pd_df[0].astype(float, copy=True)\\n    pd_df.columns = ['Reward Metric']\\n    sns.histplot(data=pd_df, bins=20, x=0, hue=1, kde=True)\\n    plt.title(f'Test', fontsize=17)\\n    #plt.xlim([0,1])\\n    plt.show()\\n    plt.figure()\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "if do_foods:\n",
    "    \n",
    "    hyper, gt = load_datasets(\n",
    "        'Foods')\n",
    "\n",
    "    hyper, gt = hyper[0], gt[0]\n",
    "    \n",
    "    print('\\nDataset info...')\n",
    "    print('The shape of the original imagery:', hyper.shape)\n",
    "    print('The shape of the original labels:', gt.shape)\n",
    "    \n",
    "# rewards\n",
    "\"\"\"    \n",
    "if do_foods:\n",
    "    num_runs = 25\n",
    "    \n",
    "    correlations = []\n",
    "    for i in range(num_runs):\n",
    "        correlations.append(calculate_correlations(hyper, num_bands_originally=hyper.shape[-1], num_bands_kept=30))\n",
    "    print(f'\\nCorrelation reward for random 30 bands, x{num_runs} runs:', np.mean(correlations))\n",
    "    \n",
    "    mis = []\n",
    "    for i in range(num_runs):\n",
    "        mis.append(calculate_mutual_infos(hyper, num_bands_originally=hyper.shape[-1], num_bands_kept=30))\n",
    "    print(f'Normalized mutual information reward for random 30 bands, x{num_runs} runs:', np.mean(mis))\n",
    "    \n",
    "    # plot rewards\n",
    "    a_string = ['pearson correlation (cumulative avg)'] * len(correlations)    \n",
    "    b_string = ['normalized mutual information (cumulative avg)'] * len(mis)\n",
    "    strings = a_string + b_string\n",
    "    pd_df = pd.DataFrame([correlations+mis, strings]).T\n",
    "    pd_df[0] = pd_df[0].astype(float, copy=True)\n",
    "    pd_df.columns = ['Reward Metric']\n",
    "    sns.histplot(data=pd_df, bins=20, x=0, hue=1, kde=True)\n",
    "    plt.title(f'Test', fontsize=17)\n",
    "    #plt.xlim([0,1])\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model performance on rescaled data (ints) with all bands...\n",
      "Validation Accuracy: 1.0\n",
      "Validation Balanced Accuracy: 1.0\n",
      "Validation Macro Averaged F1 Score: 1.0\n",
      "\n",
      "Baseline model performance on rescaled data (ints) with 30 band random subset...\n",
      "Validation Accuracy: 0.9986111111111111\n",
      "Validation Balanced Accuracy: 0.9986111111111112\n",
      "Validation Macro Averaged F1 Score: 0.9986110869980381\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# baseline models\n",
    "\n",
    "data_fpath = '../data/foods/hyperspectral_imagery/foods_hyper.npy'\n",
    "labels_fpath = '../data/foods/gt_labels/foods_gt.npy'\n",
    "\n",
    "# model with all bands included\n",
    "print(f'Baseline model performance on rescaled data (ints) with all bands...')\n",
    "acc, bac, f1 = baseline_supervised_pass(data_fpath, labels_fpath, 'Foods')\n",
    "print(f'Validation Accuracy: {acc}')\n",
    "print(f'Validation Balanced Accuracy: {bac}')\n",
    "print(f'Validation Macro Averaged F1 Score: {f1}')\n",
    "\n",
    "# model with random bands\n",
    "print(f'\\nBaseline model performance on rescaled data (ints) with {30} band random subset...')\n",
    "acc, bac, f1 = baseline_supervised_pass(data_fpath, labels_fpath, 'Foods', True, 30)\n",
    "print(f'Validation Accuracy: {acc}')\n",
    "print(f'Validation Balanced Accuracy: {bac}')\n",
    "print(f'Validation Macro Averaged F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "301faebbd5cea7fd4466786a19f1bea9d8baf657aaca95ef39840c46b8697603"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
